{
    "docs": [
        {
            "location": "/", 
            "text": "Quick start\n\n\nInstallation\n tells you how to install Rail-RNA. You can then figure out how to use it by trial and error or try the \nTutorial\n. \nDeliverables\n describes the various outputs of Rail-RNA and how to suppress ones you don't need to save time and money. \nReference\n comprehensively covers command-line parameters across all of Rail's modes and job flows.\n\n\nWhat is Rail-RNA?\n\n\nRail-RNA is a spliced alignment program: it performs intron-aware alignment of RNA sequencing (RNA-seq) data to a genome assembly. You may have heard it's designed to run in the cloud with \nAmazon Web Services\n \nElastic MapReduce\n, and you may wonder why it exists since there are already many other spliced alignment programs, so we start with an\n\n\nAdvertisement\n\n\n\n\n\n\nRail-RNA doesn't just work in the cloud; it also works on computer clusters using batch schedulers like PBS or SGE via \nIPython Parallel\n and on single computers. If ever you see Rail described as cloud-based software, don't think, \"Then it's not for me because I'm never going to use a cloud computing service\":\n\n\n\n\n\n\nRail-RNA is for almost everyone working with RNA-seq data. We observe great performance on Illumina HiSeq/MiSeq data, aligning \n= 300-bp reads to human-size genomes. Our case is laid out in \nthis paper\n.\n\n\n\n\n\n\nNever say never. We've tried to make deploying Rail on Amazon Web Services easy enough to convince you to give the cloud a chance for analyzing a large RNA-seq dataset, and we're actively working on improving user experience. Think \nfreedom through the cloud\n rather than \nfreedom from the cloud\n: while the latter attitude has its merits, with the former, you won't need to compete for compute with other users of your institutional cluster, and the extent of your analyses won't be constrained by hard upper bounds on disk space and number of processing cores.\n\n\n\n\n\n\nDo you use \na streaming music service\n, \nNetflix\n, \nwebmail\n, or \nDropbox\n? Then you can thank cloud computing for reducing processing and storage burden on your local devices. Why wouldn't you try it out for your bioinformatics too? You already use the \nUCSC Genome Browser\n.\n\n\n\n\n\n\n\n\n\n\nRail-RNA is \n(mostly)\n MIT-licensed; you can and are encouraged to hack away at it. In fact, we've tried to make this really easy for you: you can \nroll your own installer\n. The meat of the source is a bunch of Python scripts, and you can view them \nhere\n. Check out the scripts for the steps Rail-RNA executes \nhere\n). Each one has a long docstring explaining the formats of its input and output. Perhaps you'll want to mess with these scripts to tweak outputs, or you'll submit us a \npull request\n to fix a bug. (Do that, please.) Our \npaper\n and especially its supplementary material explain in detail what each step does.\n\n\n\n\n\n\nRail-RNA isn't just another aligner. While many spliced alignment programs output only SAM or BAM and perhaps a couple more text files summarizing intronic content for a single sample, Rail-RNA has several more outputs:\n\n\n\n\n\n\nbigWig\n files encoding coverage of the genome by reads in \ncoverage_bigwigs/\n. For each sample analyzed, there's one bigWig storing genome coverage by primary alignments and another storing genome coverage by uniquely aligning reads. There are also bigWigs with mean and median genome coverages across samples. To normalize each sample's contribution to these measures of center, the number of reads covering a given base of the genome is multiplied by some library size parameter (by default 40 million) and divided by the number of mapped reads in the sample. A bigWig file is an order of magnitude smaller than a BAM file---about 100 MB for 50 million reads. It can be used as input to several downstream analysis packages, including \nderfinder\n, \nedgeR-robust\n, and \nDESeq2\n. (See Leo Collado-Torres's explanation of how \nhere\n.) In fact, Rail's bigWig output is designed to work especially well with \nderfinder\n, which identifies differentially expressed regions of the genome among groups of samples. The Rail+derfinder pipeline is fully agnostic to gene annotation. Studying expression this way increases potential for discovery: in \nour Rail+\nderfinder\n reanalysis\n of the \nGEUVADIS dataset\n comprised of 667 paired-end lymphoblastoid cell line samples, 7.3% of expressed regions we uncovered occurred outside annotated genes.\n\n\n\n\n\n\nfeature matrices stored as gzipped TSV files (\ncross_sample_outputs/introns.tsv.gz\n, \ncross_sample_outputs/insertions.tsv.gz\n, and \ncross_sample_outputs/deletions.tsv.gz\n. The (i, j)th element of a given matrix is the number of reads in sample j in which evidence of feature i was found, where a feature is an intron, insertion, or deletion. A given feature matrix is straightforward to load in \nR\n with \nread.table\n.\n\n\n\n\n\n\na read count matrix \ncross_sample_outputs/read_counts.tsv\n. The (i, j)th element of this matrix contains the number of primary alignments of reads in sample i to chromosome j and the number of those alignments that are unique separated by a comma. Here, \"unique\" means that only one alignment of a given read was found to have the highest alignment score. The read count matrix is useful for normalization and required by \nderfinder\n. A supplementary normalization matrix \ncross_sample_outputs/normalization.tsv\n also provides \nupper-quartile normalization\n factors for the bigWig coverage vectors by sample.\n\n\n\n\n\n\nA \nBED\n file per sample per feature (introns, insertions, and deletions). These mirror \nTopHat 2\n's output in case you're used to them. Quotes below are from the \nTopHat 2 manual\n: \n\n\n\n\nintrons_and_indels/junctions.\nsample name\n.bed\n: \"Each junction consists of two connected BED blocks, where each block is as long as the maximal overhang of any read spanning the junction. The score is the number of alignments spanning the junction.\"\n\n\nintrons_and_indels/deletions.\nsample name\n.bed\n: \"chromLeft refers to the first genomic base of the deletion.\"\n\n\nintrons_and_indels/insertions.\nsample name\n.bed\n: \"chromLeft refers to the last genomic base before the insertion.\"\n\n\n\n\n\n\n\n\nYou can suppress any output type depending on your analysis goals, substantially reducing output size across many samples as well as the time Rail-RNA takes to run from end to end; see \nDeliverables\n. Indeed, since many RNA-seq analysis goals (e.g., differential expression) are achievable with just coverage information, it may not be necessary for you to write and release a set of unwieldy BAM files.\n\n\n\n\n\n\nRail-RNA is designed to scale well with respect to computer cluster size and input data volume. It uses the \nMapReduce\n programming model to achieve this: it divides the alignment problem up into a sequence of alternating parallelizable aggregation and computation steps, where each is performed by a different Python script operating on a different input stream. (We use \nPyPy\n to improve performance.) For a single sample on single machine, it's about as fast as TopHat 2 on 8 processing cores, but it's about twice as fast as TopHat 2 on 32 cores. Rail-RNA also\n\n\n\n\n\n\neliminates redundant alignment work giving its throughput (measured in, for example, number of samples analyzed per hour) better-than-linear scaling with respect to the number of samples analyzed; and\n\n\n\n\n\n\nborrows strength across samples in the following ways.\n\n\n\n\n\n\nRail-RNA filters out out likely false positive introns that appear in only a few samples and are covered by few reads across samples. (By default, introns that appear in \n= 5% of samples and are covered by fewer than 5 reads in any one sample are filtered out.)\n\n\n\n\n\n\nReads in all samples are automatically realigned to transcript fragments (\"isofrags\") that overlap exon-exon junctions initially found in a subset of samples. This means it's likelier that exon-exon junctions covered by a small number of reads in any given sample will be discovered.\n\n\n\n\n\n\n\n\n\n\nIf you want fast and furious with few processing cores, try \nHISAT\n, \nSTAR\n, or \nSubjunc\n. If you want to perform an integrative analysis on over 20 similar RNA-seq samples---say, from the same tissue type---give Rail a shot. We're here to help if you have questions:\n\n\n\n\n\n\nGetting help\n\n\n\n\n\n\nRead the docs\n, but you're doing that right now.\n\n\n\n\n\n\nThere's a \nGitter chat room\n where we offer live support nontrivially often. You'll need an account with GitHub to get in. Don't be scared to talk! You're encouraged to use this resource.\n\n\n\n\n\n\nYou can always email \nAbhi Nellore\n with support questions. Put \n[Rail-RNA support]\n somewhere in the subject line, and include the version of Rail-RNA you used in your support request. To find this, enter \nrail-rna --version\n.\n\n\n\n\n\n\nUse the logs and error messages to figure out what went wrong yourself. Rail's source has verbose variable names, and it should be documented well enough. Since it's just some Python, you don't have to worry about compilation, either. Add try-except blocks and rerun part of your pipeline to find lines of input a script may be stumbling on. We may ask you to do things like this in the Gitter to troubleshoot, if you're willing.\n\n\n\n\n\n\nDisclaimer\n\n\nRenting Amazon Web Services resources costs money, regardless of whether your run ultimately succeeds or fails. In some cases, Rail-RNA or its documentation may be partially to blame for a failed run. While we are happy to review bug reports, we do not accept responsibility for financial damage caused by these errors. Rail-RNA is provided \"as is\" with no warranty.", 
            "title": "Home"
        }, 
        {
            "location": "/#quick-start", 
            "text": "Installation  tells you how to install Rail-RNA. You can then figure out how to use it by trial and error or try the  Tutorial .  Deliverables  describes the various outputs of Rail-RNA and how to suppress ones you don't need to save time and money.  Reference  comprehensively covers command-line parameters across all of Rail's modes and job flows.", 
            "title": "Quick start"
        }, 
        {
            "location": "/#what-is-rail-rna", 
            "text": "Rail-RNA is a spliced alignment program: it performs intron-aware alignment of RNA sequencing (RNA-seq) data to a genome assembly. You may have heard it's designed to run in the cloud with  Amazon Web Services   Elastic MapReduce , and you may wonder why it exists since there are already many other spliced alignment programs, so we start with an", 
            "title": "What is Rail-RNA?"
        }, 
        {
            "location": "/#advertisement", 
            "text": "Rail-RNA doesn't just work in the cloud; it also works on computer clusters using batch schedulers like PBS or SGE via  IPython Parallel  and on single computers. If ever you see Rail described as cloud-based software, don't think, \"Then it's not for me because I'm never going to use a cloud computing service\":    Rail-RNA is for almost everyone working with RNA-seq data. We observe great performance on Illumina HiSeq/MiSeq data, aligning  = 300-bp reads to human-size genomes. Our case is laid out in  this paper .    Never say never. We've tried to make deploying Rail on Amazon Web Services easy enough to convince you to give the cloud a chance for analyzing a large RNA-seq dataset, and we're actively working on improving user experience. Think  freedom through the cloud  rather than  freedom from the cloud : while the latter attitude has its merits, with the former, you won't need to compete for compute with other users of your institutional cluster, and the extent of your analyses won't be constrained by hard upper bounds on disk space and number of processing cores.    Do you use  a streaming music service ,  Netflix ,  webmail , or  Dropbox ? Then you can thank cloud computing for reducing processing and storage burden on your local devices. Why wouldn't you try it out for your bioinformatics too? You already use the  UCSC Genome Browser .      Rail-RNA is  (mostly)  MIT-licensed; you can and are encouraged to hack away at it. In fact, we've tried to make this really easy for you: you can  roll your own installer . The meat of the source is a bunch of Python scripts, and you can view them  here . Check out the scripts for the steps Rail-RNA executes  here ). Each one has a long docstring explaining the formats of its input and output. Perhaps you'll want to mess with these scripts to tweak outputs, or you'll submit us a  pull request  to fix a bug. (Do that, please.) Our  paper  and especially its supplementary material explain in detail what each step does.    Rail-RNA isn't just another aligner. While many spliced alignment programs output only SAM or BAM and perhaps a couple more text files summarizing intronic content for a single sample, Rail-RNA has several more outputs:    bigWig  files encoding coverage of the genome by reads in  coverage_bigwigs/ . For each sample analyzed, there's one bigWig storing genome coverage by primary alignments and another storing genome coverage by uniquely aligning reads. There are also bigWigs with mean and median genome coverages across samples. To normalize each sample's contribution to these measures of center, the number of reads covering a given base of the genome is multiplied by some library size parameter (by default 40 million) and divided by the number of mapped reads in the sample. A bigWig file is an order of magnitude smaller than a BAM file---about 100 MB for 50 million reads. It can be used as input to several downstream analysis packages, including  derfinder ,  edgeR-robust , and  DESeq2 . (See Leo Collado-Torres's explanation of how  here .) In fact, Rail's bigWig output is designed to work especially well with  derfinder , which identifies differentially expressed regions of the genome among groups of samples. The Rail+derfinder pipeline is fully agnostic to gene annotation. Studying expression this way increases potential for discovery: in  our Rail+ derfinder  reanalysis  of the  GEUVADIS dataset  comprised of 667 paired-end lymphoblastoid cell line samples, 7.3% of expressed regions we uncovered occurred outside annotated genes.    feature matrices stored as gzipped TSV files ( cross_sample_outputs/introns.tsv.gz ,  cross_sample_outputs/insertions.tsv.gz , and  cross_sample_outputs/deletions.tsv.gz . The (i, j)th element of a given matrix is the number of reads in sample j in which evidence of feature i was found, where a feature is an intron, insertion, or deletion. A given feature matrix is straightforward to load in  R  with  read.table .    a read count matrix  cross_sample_outputs/read_counts.tsv . The (i, j)th element of this matrix contains the number of primary alignments of reads in sample i to chromosome j and the number of those alignments that are unique separated by a comma. Here, \"unique\" means that only one alignment of a given read was found to have the highest alignment score. The read count matrix is useful for normalization and required by  derfinder . A supplementary normalization matrix  cross_sample_outputs/normalization.tsv  also provides  upper-quartile normalization  factors for the bigWig coverage vectors by sample.    A  BED  file per sample per feature (introns, insertions, and deletions). These mirror  TopHat 2 's output in case you're used to them. Quotes below are from the  TopHat 2 manual :    introns_and_indels/junctions. sample name .bed : \"Each junction consists of two connected BED blocks, where each block is as long as the maximal overhang of any read spanning the junction. The score is the number of alignments spanning the junction.\"  introns_and_indels/deletions. sample name .bed : \"chromLeft refers to the first genomic base of the deletion.\"  introns_and_indels/insertions. sample name .bed : \"chromLeft refers to the last genomic base before the insertion.\"     You can suppress any output type depending on your analysis goals, substantially reducing output size across many samples as well as the time Rail-RNA takes to run from end to end; see  Deliverables . Indeed, since many RNA-seq analysis goals (e.g., differential expression) are achievable with just coverage information, it may not be necessary for you to write and release a set of unwieldy BAM files.    Rail-RNA is designed to scale well with respect to computer cluster size and input data volume. It uses the  MapReduce  programming model to achieve this: it divides the alignment problem up into a sequence of alternating parallelizable aggregation and computation steps, where each is performed by a different Python script operating on a different input stream. (We use  PyPy  to improve performance.) For a single sample on single machine, it's about as fast as TopHat 2 on 8 processing cores, but it's about twice as fast as TopHat 2 on 32 cores. Rail-RNA also    eliminates redundant alignment work giving its throughput (measured in, for example, number of samples analyzed per hour) better-than-linear scaling with respect to the number of samples analyzed; and    borrows strength across samples in the following ways.    Rail-RNA filters out out likely false positive introns that appear in only a few samples and are covered by few reads across samples. (By default, introns that appear in  = 5% of samples and are covered by fewer than 5 reads in any one sample are filtered out.)    Reads in all samples are automatically realigned to transcript fragments (\"isofrags\") that overlap exon-exon junctions initially found in a subset of samples. This means it's likelier that exon-exon junctions covered by a small number of reads in any given sample will be discovered.      If you want fast and furious with few processing cores, try  HISAT ,  STAR , or  Subjunc . If you want to perform an integrative analysis on over 20 similar RNA-seq samples---say, from the same tissue type---give Rail a shot. We're here to help if you have questions:", 
            "title": "Advertisement"
        }, 
        {
            "location": "/#getting-help", 
            "text": "Read the docs , but you're doing that right now.    There's a  Gitter chat room  where we offer live support nontrivially often. You'll need an account with GitHub to get in. Don't be scared to talk! You're encouraged to use this resource.    You can always email  Abhi Nellore  with support questions. Put  [Rail-RNA support]  somewhere in the subject line, and include the version of Rail-RNA you used in your support request. To find this, enter  rail-rna --version .    Use the logs and error messages to figure out what went wrong yourself. Rail's source has verbose variable names, and it should be documented well enough. Since it's just some Python, you don't have to worry about compilation, either. Add try-except blocks and rerun part of your pipeline to find lines of input a script may be stumbling on. We may ask you to do things like this in the Gitter to troubleshoot, if you're willing.", 
            "title": "Getting help"
        }, 
        {
            "location": "/#disclaimer", 
            "text": "Renting Amazon Web Services resources costs money, regardless of whether your run ultimately succeeds or fails. In some cases, Rail-RNA or its documentation may be partially to blame for a failed run. While we are happy to review bug reports, we do not accept responsibility for financial damage caused by these errors. Rail-RNA is provided \"as is\" with no warranty.", 
            "title": "Disclaimer"
        }, 
        {
            "location": "/installation/", 
            "text": "Installing Rail-RNA\n\n\nMake sure you have a recent (\n= 2009) Mac OS or Linux box with at least 8 GB of RAM, and download the latest version of Rail-RNA \nhere\n. If for some reason you need an older version V, you can visit https://github.com/nellore/rail/tree/master/releases, click on the file \ninstall-rail-rna-V\n, and click the \nRaw\n button to download it.\n\n\nThe file you download will be in the format \ninstall-rail-rna-V\n, where V is the version you downloaded. In a Unix shell (which you open by running the \nTerminal\n app), navigate to the directory in which you downloaded the installer. This typically means entering \ncd ~/Downloads\n. Now enter \nchmod +x install-rail-rna-V\n to make the installer executable.\n\n\nOptions\n\n\nInstallation options may now be viewed by entering \n./install-rail-rna-V\n. They include\n\n\n\n\n\n\n-i/--install-dir \ndir\n: This is the directory in which Rail-RNA should be installed. The default is \"/usr/local/raildotbio\" if you install for all users, and \"~/raildotbio\" if you install for just the current user.\n\n\n\n\n\n\n-n/--no-dependencies\n: This installs Rail-RNA without any of its dependencies. Rail-RNA wraps \nBowtie 1\n, \nBowtie 2\n, \nSAMTools\n, \nbedGraphToBigWig\n, the \nAWS CLI\n (in \nelastic\n mode, to use Rail-RNA on Amazon Elastic MapReduce), and \nIPython Parallel\n (in \nparallel\n mode, for using Rail-RNA on more than one machine in various distributed computing environments). You can avoid installing them, and Rail-RNA will then look for the appropriate dependencies, but this is not recommended.\n\n\n\n\n\n\n-p/--prep-dependencies\n: This installs Rail-RNA with only dependencies required for its preprocess job flow. The option isn't that useful: Rail-RNA invokes it in a bootstrap script in \nelastic\n mode for job flows that preprocess input data. This avoids its having to install unnecessary dependencies on cloud computing clusters. The option is overrided by \n--no-dependencies\n.\n\n\n\n\n\n\n-y/--yes\n: Ordinarily, the user is asked several questions during installation. Invoking this option answers \"yes\" to all such questions, which means Rail-RNA is installed for all users, the default installation directory \n/usr/local/raildotbio\n is overwritten if it already exists, which means you upgrade, and the AWS CLI and IPython Parallel are installed if you don't have them already.\n\n\n\n\n\n\n-s/--symlink-dependencies\n You may have already installed versions of Rail's dependencies besides the AWS CLI and IPython Parallel, like SAMTools. By default, Rail-RNA does not change your system's default executables for these dependencies, and you can go on using this software the way you always did. However, if you are installing on a new system for all users and would like to expose Rail-RNA's dependencies, invoke this option to place symlinks to dependencies in /usr/local/bin.\n\n\n\n\n\n\n--curl \nexe\n: The installer downloads with \ncURL\n, which tends to come with Linux distributions and Mac OS. It's rarely necessary to specify the path to cURL directly, but that's what this option is for.\n\n\n\n\n\n\nYou can install Rail-RNA for all users or just for the current user. If you have root access and would like to install for all users, enter\n\n\nsudo ./install-rail-rna-V\n\n\n\n\n, enter your password, and proceed. To install for just you, enter\n\n\n./install-rail-rna-V\n\n\n\n\nFollow the prompts. Rail-RNA has several dependencies: \nBowtie 1\n, \nBowtie 2\n, \nSAMTools\n, and \nbedGraphToBigWig\n are the critical ones, and they are installed especially for Rail in \n~/raildotbio\n (single-user install) or \n/usr/local/raildotbio\n (all-user install) by default. (\n-d\n may be used to specify a different destination directory, as described above). You may have some of the critical dependencies already, but the installer will copy specific versions to the destination directory anyway to ensure reproducibility of results across installations of a given version of Rail-RNA. Don't worry: nothing happens to your original configuration, and the default versions of the dependencies you already have remain default---that is, unless you invoke the \n-s\n parameter described above. Optional dependencies are the \nAWS CLI\n, which you'll need to Rail-RNA on Amazon Elastic MapReduce, and \nIPython Parallel\n, which you'll need to run Rail-RNA over a conventional computer cluster. The installer will check to see if the optional dependencies are already present. If they're not, it will ask you if you want to install them.\n\n\nThe output of a full installation for all users looks like this.\n\n\ndhcp-pool-133:Downloads testuser$ sudo ./install_rail-rna-0.1.8b \n\u2200 Rail-RNA v0.1.8b Installer\nRail-RNA can be installed for all users or just the current user.\n    * Install for all users? [y/n]: y\nInstalled Rail-RNA.\nIPython is not installed but required for Rail-RNA to work in its\n\nparallel\n mode.\n    * Install IPython now? [y/n]: y\nAWS CLI is not installed but required for Rail-RNA to work in its\n\nelastic\n mode, on Amazon Elastic MapReduce.\n    * Install AWS CLI now? [y/n]: y\nInstallation log may be found at\n/usr/local/raildotbio/rail-rna_installer.log. Configure the\nAWS CLI by running \naws configure\n. Afterwards, run\n\naws emr create-default-roles\n to use default IAM roles on Amazon\nElastic MapReduce. To learn more about IAM roles, visit\nhttp://docs.aws.amazon.com/IAM/latest/UserGuide/roles-toplevel.html .\nStart using Rail by entering \nrail-rna\n.\n\n\n\n\nIf you plan to use Rail-RNA in its \nelastic\n mode, on Amazon Elastic MapReduce, you must additionally perform the steps in the following section.\n\n\nSetting up Amazon Elastic MapReduce\n\n\nFirst off, you need an account with Amazon Web Services (AWS). Sign up \nhere\n. If you're new to AWS, we highly recommend following \nthis\n tutorial by the \nGriffith Lab\n at \nWash U\n to get a feel for its use. But if you just want to set up an account, you need only read sections 4-6 contained there.\n\n\nIf you've just installed the AWS CLI along with Rail-RNA, you must configure it. Obtain your AWS Access Key ID and Secret Access Key by following the instructions \nhere\n.\n\n\nA note on security\n\n\nDon't put your credentials in a place where anyone else can find them, especially online. Hackers will \nsteal them\n and mine cryptocurrency on your dollar.\n If you accidentally put your credentials in a GitHub repo, \nscrub it\n and \nget new AWS keys\n immediately.\n\n\nConfiguring the AWS CLI\n\n\nNow enter\n\n\naws configure\n\n\n\n\nat the shell prompt. You will be prompted to enter your Access Key ID, your Secret Access Key, and your default region. \nus-east-1\n is the standard region for US customers, and it spans data centers on the East and West Coasts. However, if you or your input data live elsewhere, you may want to default to one of the other regions listed \nhere\n. For example, we find that Rail is fastest at downloading and preprocessing data hosted by the \nEuropean Nucleotide Archive\n in the \neu-west-1\n region, which is in Ireland.\n\n\nCreating default roles\n\n\nYou must also set up \nIAM\n roles for use with Elastic MapReduce. A discussion of IAM roles for Elastic MapReduce is available \nhere\n. IAM is the way AWS securely gives users and services permission to access resources. The default set of permissions tends to work fine; if they don't for you, then you probably know enough about IAM to set up roles for Elastic MapReduce yourself. The typical way to get setting up roles over with is by entering\n\n\naws emr create-default-roles\n\n\n\n\n, but it's possible you're managing a lab whose members are IAM users attached to your AWS account, and you've already given them permissions. In this case, you will need to make sure your lab members have the \niam:GetInstanceProfile\n, \niam:GetRole\n, and \niam:PassRole\n permissions. We also recommend you give them the \niam:ListRoles\n permission; otherwise, they won't be able clone clusters on Elastic MapReduce. This is sometimes useful if their job flows fail because their bid prices on the \nspot market\n were too low, and they want to restart job flows easily. With the appropriate permissions, lab members can install Rail-RNA and configure the AWS CLI as described above. This includes their running \naws emr create-default-roles\n, which will retrieve the default roles you created for them. Learn more about working with IAM users \nhere\n. This step, and if you find yourself having trouble, ask for help in our \nGitter\n.\n\n\nHow the installer works\n\n\nThe Rail-RNA installer is nothing but a ZIP archive. When it is executed by Python while it's still compressed, the installer is run. If you unpack the archive first and then execute the directory containing \n__main__.py\n, Rail-RNA is run, and it will complain if it can't find dependencies. If you're a Python developer who needs to write a custom installer because your software is difficult to package with something like \npip\n, you might want to try this approach. A helpful starting point is \nthis page\n.\n\n\nRolling your own installer\n\n\nWe've made it easy for you to release your own custom version of Rail-RNA.\n\n\n\n\n\n\nClone the source at a shell prompt with\n\n\ngit clone https://www.github.com/nellore/rail.git\n\n\n\n. We assume you cloned to \n/home/testuser/rail\n below\n\n\n\n\n\n\nEdit \nsrc/version.py\n, which looks like this:\n        #!/usr/bin/env python\n        \"\"\"\n        version.py\n        Part of Rail-RNA\n\n\nStores version number of Rail-RNA as a string.\n\"\"\"\n\nversion_number = 'devel'\n\n\n\nChange \"devel\" to some version number that diverges from the Rail-RNA versioning scheme. Perhaps you'll use a prefix \"C\" for \"custom,\" as in \"C0.1.0\". We call your custom version C below.\n\n\n\n\n\n\nEdit source files in \nsrc/\n however you want. You'll probably want to focus on the files in \nsrc/rna/steps\n, which contains a script per step of the Rail-RNA pipeline. To test your changes, rather than starting a command with \nrail-rna\n, use\n        python /home/testuser/rail/src\n.\n\n\n\n\n\n\nOnce you're done hacking Rail, run\n        sh /home/testuser/rail/make_it_rail.sh\nA new installer \ninstall-rail-rna-C\n will appear in the \nreleases/\n directory. Run it to install your modified version locally.", 
            "title": "Installation"
        }, 
        {
            "location": "/installation/#installing-rail-rna", 
            "text": "Make sure you have a recent ( = 2009) Mac OS or Linux box with at least 8 GB of RAM, and download the latest version of Rail-RNA  here . If for some reason you need an older version V, you can visit https://github.com/nellore/rail/tree/master/releases, click on the file  install-rail-rna-V , and click the  Raw  button to download it.  The file you download will be in the format  install-rail-rna-V , where V is the version you downloaded. In a Unix shell (which you open by running the  Terminal  app), navigate to the directory in which you downloaded the installer. This typically means entering  cd ~/Downloads . Now enter  chmod +x install-rail-rna-V  to make the installer executable.  Options  Installation options may now be viewed by entering  ./install-rail-rna-V . They include    -i/--install-dir  dir : This is the directory in which Rail-RNA should be installed. The default is \"/usr/local/raildotbio\" if you install for all users, and \"~/raildotbio\" if you install for just the current user.    -n/--no-dependencies : This installs Rail-RNA without any of its dependencies. Rail-RNA wraps  Bowtie 1 ,  Bowtie 2 ,  SAMTools ,  bedGraphToBigWig , the  AWS CLI  (in  elastic  mode, to use Rail-RNA on Amazon Elastic MapReduce), and  IPython Parallel  (in  parallel  mode, for using Rail-RNA on more than one machine in various distributed computing environments). You can avoid installing them, and Rail-RNA will then look for the appropriate dependencies, but this is not recommended.    -p/--prep-dependencies : This installs Rail-RNA with only dependencies required for its preprocess job flow. The option isn't that useful: Rail-RNA invokes it in a bootstrap script in  elastic  mode for job flows that preprocess input data. This avoids its having to install unnecessary dependencies on cloud computing clusters. The option is overrided by  --no-dependencies .    -y/--yes : Ordinarily, the user is asked several questions during installation. Invoking this option answers \"yes\" to all such questions, which means Rail-RNA is installed for all users, the default installation directory  /usr/local/raildotbio  is overwritten if it already exists, which means you upgrade, and the AWS CLI and IPython Parallel are installed if you don't have them already.    -s/--symlink-dependencies  You may have already installed versions of Rail's dependencies besides the AWS CLI and IPython Parallel, like SAMTools. By default, Rail-RNA does not change your system's default executables for these dependencies, and you can go on using this software the way you always did. However, if you are installing on a new system for all users and would like to expose Rail-RNA's dependencies, invoke this option to place symlinks to dependencies in /usr/local/bin.    --curl  exe : The installer downloads with  cURL , which tends to come with Linux distributions and Mac OS. It's rarely necessary to specify the path to cURL directly, but that's what this option is for.    You can install Rail-RNA for all users or just for the current user. If you have root access and would like to install for all users, enter  sudo ./install-rail-rna-V  , enter your password, and proceed. To install for just you, enter  ./install-rail-rna-V  Follow the prompts. Rail-RNA has several dependencies:  Bowtie 1 ,  Bowtie 2 ,  SAMTools , and  bedGraphToBigWig  are the critical ones, and they are installed especially for Rail in  ~/raildotbio  (single-user install) or  /usr/local/raildotbio  (all-user install) by default. ( -d  may be used to specify a different destination directory, as described above). You may have some of the critical dependencies already, but the installer will copy specific versions to the destination directory anyway to ensure reproducibility of results across installations of a given version of Rail-RNA. Don't worry: nothing happens to your original configuration, and the default versions of the dependencies you already have remain default---that is, unless you invoke the  -s  parameter described above. Optional dependencies are the  AWS CLI , which you'll need to Rail-RNA on Amazon Elastic MapReduce, and  IPython Parallel , which you'll need to run Rail-RNA over a conventional computer cluster. The installer will check to see if the optional dependencies are already present. If they're not, it will ask you if you want to install them.  The output of a full installation for all users looks like this.  dhcp-pool-133:Downloads testuser$ sudo ./install_rail-rna-0.1.8b \n\u2200 Rail-RNA v0.1.8b Installer\nRail-RNA can be installed for all users or just the current user.\n    * Install for all users? [y/n]: y\nInstalled Rail-RNA.\nIPython is not installed but required for Rail-RNA to work in its parallel  mode.\n    * Install IPython now? [y/n]: y\nAWS CLI is not installed but required for Rail-RNA to work in its elastic  mode, on Amazon Elastic MapReduce.\n    * Install AWS CLI now? [y/n]: y\nInstallation log may be found at\n/usr/local/raildotbio/rail-rna_installer.log. Configure the\nAWS CLI by running  aws configure . Afterwards, run aws emr create-default-roles  to use default IAM roles on Amazon\nElastic MapReduce. To learn more about IAM roles, visit\nhttp://docs.aws.amazon.com/IAM/latest/UserGuide/roles-toplevel.html .\nStart using Rail by entering  rail-rna .  If you plan to use Rail-RNA in its  elastic  mode, on Amazon Elastic MapReduce, you must additionally perform the steps in the following section.", 
            "title": "Installing Rail-RNA"
        }, 
        {
            "location": "/installation/#setting-up-amazon-elastic-mapreduce", 
            "text": "First off, you need an account with Amazon Web Services (AWS). Sign up  here . If you're new to AWS, we highly recommend following  this  tutorial by the  Griffith Lab  at  Wash U  to get a feel for its use. But if you just want to set up an account, you need only read sections 4-6 contained there.  If you've just installed the AWS CLI along with Rail-RNA, you must configure it. Obtain your AWS Access Key ID and Secret Access Key by following the instructions  here .  A note on security  Don't put your credentials in a place where anyone else can find them, especially online. Hackers will  steal them  and mine cryptocurrency on your dollar.  If you accidentally put your credentials in a GitHub repo,  scrub it  and  get new AWS keys  immediately.  Configuring the AWS CLI  Now enter  aws configure  at the shell prompt. You will be prompted to enter your Access Key ID, your Secret Access Key, and your default region.  us-east-1  is the standard region for US customers, and it spans data centers on the East and West Coasts. However, if you or your input data live elsewhere, you may want to default to one of the other regions listed  here . For example, we find that Rail is fastest at downloading and preprocessing data hosted by the  European Nucleotide Archive  in the  eu-west-1  region, which is in Ireland.  Creating default roles  You must also set up  IAM  roles for use with Elastic MapReduce. A discussion of IAM roles for Elastic MapReduce is available  here . IAM is the way AWS securely gives users and services permission to access resources. The default set of permissions tends to work fine; if they don't for you, then you probably know enough about IAM to set up roles for Elastic MapReduce yourself. The typical way to get setting up roles over with is by entering  aws emr create-default-roles  , but it's possible you're managing a lab whose members are IAM users attached to your AWS account, and you've already given them permissions. In this case, you will need to make sure your lab members have the  iam:GetInstanceProfile ,  iam:GetRole , and  iam:PassRole  permissions. We also recommend you give them the  iam:ListRoles  permission; otherwise, they won't be able clone clusters on Elastic MapReduce. This is sometimes useful if their job flows fail because their bid prices on the  spot market  were too low, and they want to restart job flows easily. With the appropriate permissions, lab members can install Rail-RNA and configure the AWS CLI as described above. This includes their running  aws emr create-default-roles , which will retrieve the default roles you created for them. Learn more about working with IAM users  here . This step, and if you find yourself having trouble, ask for help in our  Gitter .", 
            "title": "Setting up Amazon Elastic MapReduce"
        }, 
        {
            "location": "/installation/#how-the-installer-works", 
            "text": "The Rail-RNA installer is nothing but a ZIP archive. When it is executed by Python while it's still compressed, the installer is run. If you unpack the archive first and then execute the directory containing  __main__.py , Rail-RNA is run, and it will complain if it can't find dependencies. If you're a Python developer who needs to write a custom installer because your software is difficult to package with something like  pip , you might want to try this approach. A helpful starting point is  this page .", 
            "title": "How the installer works"
        }, 
        {
            "location": "/installation/#rolling-your-own-installer", 
            "text": "We've made it easy for you to release your own custom version of Rail-RNA.    Clone the source at a shell prompt with  git clone https://www.github.com/nellore/rail.git  . We assume you cloned to  /home/testuser/rail  below    Edit  src/version.py , which looks like this:\n        #!/usr/bin/env python\n        \"\"\"\n        version.py\n        Part of Rail-RNA  Stores version number of Rail-RNA as a string.\n\"\"\"\n\nversion_number = 'devel'  Change \"devel\" to some version number that diverges from the Rail-RNA versioning scheme. Perhaps you'll use a prefix \"C\" for \"custom,\" as in \"C0.1.0\". We call your custom version C below.    Edit source files in  src/  however you want. You'll probably want to focus on the files in  src/rna/steps , which contains a script per step of the Rail-RNA pipeline. To test your changes, rather than starting a command with  rail-rna , use\n        python /home/testuser/rail/src\n.    Once you're done hacking Rail, run\n        sh /home/testuser/rail/make_it_rail.sh\nA new installer  install-rail-rna-C  will appear in the  releases/  directory. Run it to install your modified version locally.", 
            "title": "Rolling your own installer"
        }, 
        {
            "location": "/tutorial/", 
            "text": "All examples in this tutorial were generated by \nFlux Simulator\n with \nthis\n script from the Rail repo.\n\n\nTrial and error\n\n\nWe made a serious attempt to design Rail-RNA for people who don't read manuals to discourage improper use of the software. In general, you can get started by entering\n\n\nrail-rna\n\n\n\n\nin the shell. You'll obtain the following output, perhaps with a different version number.\n\n\nerror: too few arguments\nusage: rail-rna \njob flow\n \nmode\n \n[args]\n\n\n  \njob flow\n       {prep, align, go}\n                     prep: preprocess reads listed in a required manifest\n                       file (specified with --manifest)\n                     align: align preprocessed reads (specified with --input)\n                     go: perform prep and align in succession\n  \nmode\n           {local, parallel, elastic}\n                     local: run Rail-RNA on this computer\n                     parallel: run Rail-RNA on all active IPython engines\n                     elastic: run Rail-RNA on Amazon Elastic MapReduce.\n                       Requires that the user sign up for Amazon Web Services\n\n\u2200 Rail-RNA v0.1.8c by Abhi Nellore (anellore@jhu.edu; nellore.github.io)\n\nRail-RNA is a scalable MapReduce pipeline that can analyze many RNA-seq\ndatasets at once. To view help for a given combination of \njob flow\n and\n\nmode\n, specify both, then add -h/--help.\n\n\n\n\nIt's quite possible to figure out how a substantial fraction Rail-RNA works by trial and error. Follow the prompts and fix your errors, which Rail tries to explain in detail when they're encountered. Please let us know in the \nGitter\n if you're confused by any errors output. If you prefer to be guided through some examples, read on.\n\n\nModes and job flows\n\n\nRail-RNA has three modes---\n\n\n\n\n\n\nlocal\n, which runs the software on a single machine on up to as many processing cores as available. By default, Rail-RNA runs on the number of processing cores it detects on a machine less one to avoid monopolizing a single machine's resources. To adjust the number of cores on which Rail is run, use the \n-p/--num-processes\n command-line parameter described under Reference.\n\n\n\n\n\n\nelastic\n, which runs the software on an Amazon Elastic MapReduce computer cluster in the cloud. This costs money: you rent computing capacity (on \nElastic Compute Cloud\n, or EC2) and storage (on \nSimple Storage Service\n, or S3) from Amazon for the duration of your job flow and for as long as you keep your outputs in the cloud. Price information is \nhere\n. For a medium-size job (up to ~100 RNA-seq samples with ~50 million reads each), we tend to use a cluster of 40 c3.2xlarge machines, which costs $21/hour on demand but perhaps less than half that number on the spot market in the US Standard zone (\nus-east-1\n). Learn more about the spot market and bidding on compute capacity \nhere\n.\n\n\n\n\n\n\nparallel\n, which runs on an IPython Parallel cluster whose profile is specified at the command line. You must set up the IPython Parallel cluster yourself.\n\n\n\n\n\n\n---and three job flows---\n\n\n\n\n\n\nprep\n, which if necessary downloads input FASTQ/FASTA files from a remote server and casts it in a form amenable for further analysis. This job flow must always be run before the \nalign\n job flow.\n\n\n\n\n\n\nalign\n, which aligns preprocessed data and writes outputs explained in \nDeliverables\n. Use the \n--deliverables\n option described there to control which of Rail-RNA's terminal outputs should be written.\n\n\n\n\n\n\ngo\n, which runs the \nprep\n and \nalign\n job flows in succession.\n\n\n\n\n\n\nTo run some combination of mode and job flow, start your command with\n\n\nrail-rna \nmode\n \njob flow\n\n\n\n\n\n. Get help by entering\n\n\nrail-rna \nmode\n \njob flow\n -h\n\n\n\n\nThe reason for separating the \nprep\n and \nalign\n job flows is that you may prefer to run these flows on different numbers of processing cores: if downloads are throttled by the remote server, and only a small number of threads can download input files concurrently, then you can limit the size of the computer cluster in \nelastic\n mode (with the \n-c/--core-instance-count\n parameter described in Reference) or the number of concurrently running threads in \nlocal\n mode (with the \n-p/--num-processes\n parameter described in Reference).\n\n\nAlign some RNA-seq samples with us in \nlocal\n, \nparallel\n, and \nelastic\n modes below. We assume your login name is \ntestuser\n, and your home directory is \n/home/testuser\n.\n\n\nlocal\n and \nparallel\n modes: Drosophila examples\n\n\nRail-RNA wraps both \nBowtie 1\n and \nBowtie 2\n, so you will need \nboth\n Bowtie 1 and Bowtie 2 indexes of a genome assembly to perform alignment. It's easiest to download one of the \nIllumina iGenomes\n, collections of reference sequences and indexes for popularly studied organisms. Here are explicit instructions:\n\n\nDownload the Drosophila melanogaster build dm3 iGenome, available \nhere\n. This is a 783-MB file. We assume you downloaded the dm3 iGenome to the directory \n/home/testuser/Downloads\n. Unpack it by entering\n\n\ncd /home/testuser/Downloads\ntar xvzf Drosophila_melanogaster_UCSC_dm3.tar.gz\n\n\n\n\nin the shell. This could take a while, but once it's done, the Bowtie 1 index basename should be \n/home/testuser/Downloads/Drosophila_melanogaster/UCSC/dm3/Sequence/BowtieIndex/genome\n, while the Bowtie 2 index basename should be \n/home/testuser/Downloads/Drosophila_melanogaster/UCSC/dm3/Sequence/Bowtie2Index/genome\n.\n\n\nWarning:\n You may think you already have Bowtie 1 and 2 indexes for a given genome assembly---perhaps dm3---but the contigs in one may not be exactly the same as the contigs in the other. When working with any reference in Rail-RNA, it is important to ensure that the Bowtie 1 and 2 indexes are built from the same FASTA. Check the \nBowtie 1 documentation\n and \nBowtie 2 documentation\n for information on how to build Bowtie indexes from reference FASTAs.\n\n\nNow open your browser, and navigate to the URL https://raw.githubusercontent.com/nellore/rail/master/ex/dm3_example.manifest . You'll see the following text.\n\n\nhttp://verve.webfactional.com/dm3_example_1_left.fastq       0       http://verve.webfactional.com/dm3_example_1_right.fastq        0       dm3_example-1-1\nhttp://verve.webfactional.com/dm3_example_2_left.fastq       0       http://verve.webfactional.com/dm3_example_2_right.fastq        0       dm3_example-2-1\n\n\n\n\nThis is a Rail-RNA manifest file, and it is required for all Rail-RNA runs. Its format mirrors the manifest file format of \nMyrna\n, a predecessor of Rail. Each line corresponds to a different RNA-seq sample. A line for a single-end sample looks like this---\n\n\nFASTQ/FASTA URL\n(tab)\nURL MD5 checksum or 0\n(tab)\nsample label\n\n\n\n\n\n---while a line for a paired-end sample looks like this---\n\n\nFASTQ/FASTA URL 1\n(tab)\nURL 1 MD5 checksum or 0\n(tab)\nFASTQ/FASTA URL 2\n(tab)\nURL 2 MD5 checksum or 0\n(tab)\nsample label\n\n\n\n\n\n. URLs can be on the local filesystem, on the web, or if the \nAWS CLI\n is installed, on Amazon S3. If an input file is not on the local filesystem, it will be downloaded by Rail. Manifest files may be hosted remotely as well.\n\n\nOur Drosophila example is composed of two paired-end biological replicates, and the raw data is hosted at \nhttp://verve.webfactional.com\n . Let's create a new \nrailtests\n directory in \ntestuser\n's home directory for running all our examples. \n\n\nmkdir -p /home/testuser/railtests\ncd /home/testuser/railtests\n\n\n\n\nPreprocessing and aligning the test data in \nlocal\n mode takes a single command:\n\n\nrail-rna go local -x /home/testuser/Downloads/Drosophila_melanogaster/UCSC/dm3/Sequence/BowtieIndex/genome /home/testuser/Downloads/Drosophila_melanogaster/UCSC/dm3/Sequence/Bowtie2Index/genome -m https://raw.githubusercontent.com/nellore/rail/master/ex/dm3_example.manifest\n\n\n\n\n. The run should complete after a few minutes. You can browse the output by entering\n\n\ncd /home/testuser/railtests/rail-rna_out\nls\n\n\n\n\nYou'll find four directories:\n\n\nalignments    cross_sample_results\ncoverage_bigwigs  introns_and_indels\n\n\n\n\nSee \nDeliverables\n for information on how to interpret what's in these directories.\n\n\nCommonly used options in \nlocal\n mode are\n\n \n-p/--num-processes\n, which controls the number of processes Rail-RNA runs simultaneously. By default, Rail uses as many processing cores as your computer has less one so it doesn't monopolize resources. You may want to run on all cylinders by setting this equal to the number of available processing cores.\n\n \n-o/--output\n, which changes the output directory. By default, this is \nrail-rna_out\n in the current directory.\n\n\nSee the Reference section for a comprehensive description of command-line parameters.\n\n\nWe could have run Rail-RNA in two steps: by preprocessing first and subsequently aligning. You can try this yourself by running the following commands in sequence.\n\n\ncd /home/testuser/railtests\nrail-rna prep local -m https://raw.githubusercontent.com/nellore/rail/master/ex/dm3_example.manifest -o dmel_prepped -p 1\nrail-rna align local -i dmel_prepped -m https://raw.githubusercontent.com/nellore/rail/master/ex/dm3_example.manifest -x home/testuser/Downloads/Drosophila_melanogaster/UCSC/dm3/Sequence/BowtieIndex/genome /home/testuser/Downloads/Drosophila_melanogaster/UCSC/dm3/Sequence/Bowtie2Index/genome -f\n\n\n\n\nThe \nrail-rna prep local\n command above is executed on a single thread (with \n-p 1\n) to ensure that only one download is performed at a time, which would be useful if our downloads were throttled. In the \nrail-rna align local\n command, the parameter \n-f/--force\n tells Rail to overwrite any existing outputs. You should end up with exactly the same output you obtained when you ran the \nrail-rna go local\n command.\n\n\nNow you'll run an example that will break Rail. Navigate to the URL https://raw.githubusercontent.com/nellore/rail/master/ex/bad.manifest . The manifest will look like this:\n\n\nhttp://verve.webfactional.com/bad.fastq       0        bad-1-1\n\n\n\n\nIt's a single-end sample called \"bad,\" presumably because it's not good. Visit http://verve.webfactional.com/bad.fastq next. The file will be downloaded, or it will be displayed in your browser. If it's downloaded, navigate to the appropriate folder at the shell prompt, and enter\n\n\ncat bad.fastq\n\n\n\n\n. Either way, you'll see\n\n\n@badrecord\nATACAGATGACAGATGACAGGGTAGAGACAAATAGACAGATGACGATGGACAGATGACAGATAGAACAGATAGAGA\n+\nIIIIIIIIIIIIII\n@goodrecord\nATGGCATCAGTCAAGTCAAGATTACTAGTAGCCATACAAGATACATCGTTTAACGATTGTGGCACATACGTCACCA\n+\nIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII\n\n\n\n\nThere's one sequence labeled \"badrecord\" and another labeled \"goodrecord\". \"badrecord\" is bad because its read sequence isn't the same length as its quality sequence. Without being told otherwise, Rail-RNA chokes on bad records, but it's good to see how it chokes to learn how to diagnose problems. Run Rail-RNA on the bad manifest like so---\n\n\ncd /home/testuser/railtests\nrail-rna go local -x /home/testuser/Downloads/Drosophila_melanogaster/UCSC/dm3/Sequence/BowtieIndex/genome /home/testuser/Downloads/Drosophila_melanogaster/UCSC/dm3/Sequence/Bowtie2Index/genome -m https://raw.githubusercontent.com/nellore/rail/master/ex/bad.manifest -o ./bad\n\n\n\n\n---and you'll ultimately obtain output like this:\n\n\n\u2200 Rail-RNA v0.1.8c\nStarted job flow on Saturday, Jul 18, 2015 at 07:36:29 PM EDT.\n\n~.oOo.\n\n\n00h:00m:00s |___| Step 1/24: Count lines in input files\n00h:00m:01s |___|     Completed 1 task.\n00h:00m:01s |___|     Deleted temporary files.\n00h:00m:01s |___| Step 2/24: Assign reads to preprocessing tasks\n00h:00m:01s |___|     Partitioned 1 input into tasks.\n00h:00m:03s |___|     Completed 1 task.\n00h:00m:03s |___|     Deleted temporary files.\n00h:00m:03s |___| Step 3/24: Preprocess reads\n*****Errors encountered*****\nStreaming command \ncat /var/folders/rs/zytvc1753p9_bth4lrhbm7c80000gn/T/tmpCxbBKB/0 | /usr/local/raildotbio/pypy-2.5.0-osx64/bin/pypy /usr/local/raildotbio/rail-rna/rna/steps/preprocess.py --nucs-per-file=100000000 --gzip-output --push=/home/testuser/railtests/rail-rna_logs/preprocess/push --gzip-level 3   --bin-qualities \n/home/testuser/railtests/rail-rna_logs/preprocess/0 2\n/home/testuser/railtests/rail-rna_logs/preprocess/dp.map.log/0.0.log\n failed; exit level was 1.\nJob flow failed on Saturday, Jul 18, 2015 at 07:36:34 PM EDT. Run time was 5.503 seconds.\nTo start this job flow from where it left off, run:\n/usr/local/raildotbio/pypy-2.5.0-osx64/bin/pypy /usr/local/raildotbio/rail-rna/dooplicity/emr_simulator.py -j /home/testuser/railtests/rail-rna_logs/resume_flow_WDEZ24GVC0TM.json -b /usr/local/raildotbio/rail-rna/rna/driver/rail-rna.txt -l /home/testuser/railtests/rail-rna_logs/flow.2015-07-18T19:36:27.934937.log -f --max-attempts 1 --num-processes 3\nTraceback (most recent call last):\n  File \napp_main.py\n, line 75, in run_toplevel\n  File \n/usr/local/raildotbio/rail-rna/dooplicity/emr_simulator.py\n, line 1963, in \nmodule\n\n    args.scratch, args.common, args.sort, args.max_attempts)\n  File \n/usr/local/raildotbio/rail-rna/dooplicity/emr_simulator.py\n, line 1719, in run_simulation\n    max_attempts=max_attempts\n  File \n/usr/local/raildotbio/rail-rna/dooplicity/emr_simulator.py\n, line 1290, in execute_balanced_job_with_retries\n    raise RuntimeError\nRuntimeError\n\n\n\n\nRail is telling us that something went wrong with a command during preprocessing. Note the following.\n\n\n\n\n\n\nRail gives you a command you can use to resume a job flow if it's failed for a fixable reason. One possible reason is that you ran out of space on disk during a job flow, and you need to delete some of your files. You can highlight and copy the command that resumes your job flow with \nCommand+C\n on a Mac or \nCTRL+C\n in Linux. If somehow you lose the resume command, you'll also find it in the last written file whose extension is \n.log\n in the log directory \n/home/testuser/railtests/rail-rna_logs\n. Enter \n\n\nls -tr /home/testuser/railtests/rail-rna_logs/*.log | tail -n 1\n\n\n\nto get its path.\n\n\n\n\n\n\nThere's a log file in the command that failed, right after the \n2\n. This file will tell you why the job flow failed. Open it with \nless\n:\n\n\nless /home/testuser/dmel/rail-rna_logs/preprocess/dp.map.log/0.0.log\n\n\n\n. (You should \nless\n whatever log file appears for you after the \n2\n). At the bottom of the file is the exception that made the job flow fail:\n\n\nCreated local destination directory \"/var/folders/rs/zytvc1753p9_bth4lrhbm7c80000gn/T/tmpQJHduB\".\nRetrieving URL \"http://verve.webfactional.com/bad.fastq\"...\nRange of quality values found from random sample of 10000 records is (73, 73).\nGuessed Phred64 encoding.\nTraceback (most recent call last):\n  File \"app_main.py\", line 75, in run_toplevel\n  File \"/usr/local/raildotbio/rail-rna/rna/steps/preprocess.py\", line 863, in \nmodule\n\n    mover=mover)\n  File \"/usr/local/raildotbio/rail-rna/rna/steps/preprocess.py\", line 557, in go\n    ) % (line_numbers[i], sources[i])\nAssertionError: Length of read sequence does not match length of quality string at line 4 of file \"/var/folders/rs/zytvc1753p9_bth4lrhbm7c80000gn/T/tmpQJHduB/bad.fastq\".\n\n\n\n. So Rail noticed \n@badrecord\n was a bad record and failed. You can have Rail ignore bad records during preprocessing using the \n--ignore-bad-records\n command-line parameter:\n\n\nrail-rna go local -x /home/testuser/Downloads/Drosophila_melanogaster/UCSC/dm3/Sequence/BowtieIndex/genome /home/testuser/Downloads/Drosophila_melanogaster/UCSC/dm3/Sequence/Bowtie2Index/genome -m https://raw.githubusercontent.com/nellore/rail/master/ex/bad.manifest -o ./bad -f --ignore-bad-records\n\n\n\n. This job flow should succeed, and you'll end up with exactly one aligned read in the directory \n/home/testuser/railtests/bad/alignments\n. Ignoring bad records may be useful when you're analyzing hundreds of samples and, for example, one file is truncated, but you'd like to analyze all its available reads anyway. Sometimes, you can't anticipate the integrity of the data you're analyzing, but you don't want your job flow to fail because of a handful of bad records.\n\n\n\n\n\n\nTo test Rail-RNA in \nparallel\n mode, you should have IPython installed. If the Rail-RNA installer didn't prompt you to install it, you already have it. Detailed instructions on starting IPython clusters over many different cluster configurations may be found \nhere\n. The IPython documentation around this link teaches you how to create a profile for a cluster configuration and how to start a cluster. An IPython cluster is nothing but a collection of Python interpreters (\"engines\") running on processing cores distributed across some networked computers. Rail-RNA does not start an IPython cluster for you; rather, it detects a running IPython cluster and runs itself over that. You can choose the IPython profile Rail-RNA should use with the \n--ipython-profile\n command-line parameter. If left unspecified, this is taken to be the default profile.\n\n\nFor testing purposes, you can run an IPython cluster on just your machine by entering\n\n\nipcluster start -n \nk\n\n\n\n\n\n, where \nk\n is the number of IPython engine processes you want to run. \nk\n is analogous to the \n-p/--num-processes\n parameter of Rail-RNA in local mode. Now rerun the first Drosophila example except in \nparallel\n mode by entering\n\n\nrail-rna go parallel -x /home/testuser/Downloads/Drosophila_melanogaster/UCSC/dm3/Sequence/BowtieIndex/genome /home/testuser/Downloads/Drosophila_melanogaster/UCSC/dm3/Sequence/Bowtie2Index/genome -m https://raw.githubusercontent.com/nellore/rail/master/ex/dm3_example.manifest -f\n\n\n\n\nWhat happens is pretty unimpressive: Rail runs like it does in local mode. But IPython Parallel lends Rail versatility: there are many different IPython cluster configurations you can set up on, say, your institutional computer cluster. But there is one caveat: in \nparallel\n mode, you \nmust\n make sure the output directory (specified with \n-o/--output\n) and the log directory (specified with \n--log\n) are at paths accessible to \nall\n the nodes in your cluster running IPython engines. Rail-RNA aggregates intermediate data in the log directory between any two successive steps, and all nodes must be able to stream data from that directory to complete their assigned tasks. Moreover, outputs must go to the same place, and some paths on a cluster refer to different places on different nodes. For example, you probably shouldn't make a subdirectory of \n/tmp\n your output or log directory on a conventional computer cluster because \n/tmp\n tends to be a node-local temporary directory.\n\n\nelastic\n mode: a human example\n\n\nWarning: running this example will cost money\n, but probably no more than US$5. Read our \ndisclaimer\n before using \nelastic\n mode.\n\n\nYou should have performed \nthese\n steps to set up the AWS CLI and Elastic MapReduce before attempting the example.\n\n\nVisit https://raw.githubusercontent.com/nellore/rail/master/ex/hg19_example.manifest in your browser. Listed are two single-end human samples with just 20,000 reads each. They were generated with expression profiles of two \nGEUVADIS\n lymphoblastoid cell line samples in a way we describe in our \npaper\n, but because there are so few reads, you probably couldn't tell which GEUVADIS samples we used if you didn't have the sample labels in the manifest file.\n\n\nLet's use Elastic MapReduce to both preprocess and align these data. Since you'll be storing the results on Amazon's \nSimple Storage Service\n (S3), you should first read up on \nworking with buckets\n. The short story is that on S3, a bucket is something like a directory in a filesystem, except\n\n\n\n\nUnless you specify otherwise, only your account can access it.\n\n\nBucket names are globally unique: if someone else has taken a bucket name in any Amazon region, you can't have it.\n\n\nUnderscores in bucket names are a bad idea when you use Elastic MapReduce. They cause weird problems. Don't ask why; just go with it.\n\n\nA bucket is located in a specific Amazon region---that is, a bucket has a physical location in an Amazon data center, and that's where your files go.\n\n\n\n\nYou can create a bucket at the command line using the AWS CLI. Enter\n\n\naws s3 mb s3://this-is-the-bucket-name-you-make-up --region \na valid region\n\n\n\n\n\n. A list of valid regions is available \nhere\n. Since you specified your default region when configuring the AWS CLI, if you leave the \n--region\n part out above, the bucket will be created in your default region---typically \nus-east-1\n.\n\n\nBut you don't \nhave\n to create a bucket yourself before using Rail; if it doesn't already exist, Rail will automatically create the bucket you specify in your output directory path for you. We went through this exercise so you understand that the root of your output directory on S3 will always be a bucket in some region. Note that you can use Amazon's \nweb interface\n to manipulate buckets, too.\n\n\nIf you've set up the AWS CLI properly, you can preprocess and align the example human dataset in the cloud with one command:\n\n\nrail-rna go elastic -m https://raw.githubusercontent.com/nellore/rail/master/ex/hg19_example.manifest -a hg19 -o s3://this-is-the-bucket-name-you-make-up/human_example --core-instance-type c3.2xlarge --master-instance-type c3.2xlarge -c 1\n\n\n\n\n. This command reserves two \nc3.2xlarge\n EC2 instances\n to execute a Rail-RNA job flow that dumps its output to \ns3://this-is-the-bucket-name-you-make-up/human_example\n. =There's always one master instance, whose type is specified with the \n--master-instance-type\n command-line parameter above; and the \n-c\n parameter specifies the number of core instances, whose type is specified with \n--core-instance-type\n. The master instance manages the Hadoop cluster that will run your job, scheduling and coordinating tasks that are executed on slave nodes---which for Rail-RNA are generally core instances. We recommend using at least 40 \nc3.2xlarge\n core instances for every hundred RNA-seq samples with 50 million reads each. You might also consider using \nc3.8xlarge\n instances, each of which has four times the resources of a \nc3.2xlarge\n instance; so in this case, the recommended ratio is at least 10 \nc3.8xlarge\n instances for every hundred RNA-seq samples with 50 million reads each. For our small example, we use only one core instance. The \n-a hg19\n parameter specifies that the input data should be aligned to hg19.\n\n\nWarning\n: Your job flow will execute in the default region you chose when you set up the AWS CLI unless you tack a \n--region \ndesired region\n onto the command above. If your output bucket is in a region different from your Elastic MapReduce cluster, transferring data between the cluster and S3 will take longer and slow down your job. \n\n\nExecuting the \nrail-rna go elastic ...\n command above gives the following output.\n\n\ntestcomputer:~ testuser$ rail-rna go elastic -m https://raw.githubusercontent.com/nellore/rail/master/ex/hg19_example.manifest -a hg19 -o s3://this-is-the-bucket-name-you-make-up/human_example --core-instance-type c3.2xlarge --master-instance-type c3.2xlarge -c 1\nLoading...\nChecked all files listed in manifest file.\nCopied Rail-RNA and bootstraps to S3.\n\n\u2200 Rail-RNA v0.1.8c\nStarted job flow submission script on Saturday, Jul 18, 2015 at 08:50:34 PM EDT.\n\n~.oOo.\n\n\n00h:00m:00s |___| Read job flow from input JSON.\n00h:00m:10s |___| Verified that output directories on S3 are writable.\n00h:00m:23s |___| Set up output directories on S3.\n00h:00m:25s |___| Submitted job flow.\n*****Job flow ID is j-2NSJ3SJPGKC58 .*****\n*****Submission can be monitored at https://console.aws.amazon.com/elasticmapreduce/?region=eu-west-1#cluster-details:j-2NSJ3SJPGKC58 .*****\n00h:00m:25s |___| Opening URL in default browser, if possible.\n\n\n.oOo.~\n\nFinished job flow submission script on Saturday, Jul 18, 2015 at 08:51:00 PM EDT. Run time was 25.789 seconds.\n\n\n\n\nIf all goes well, your browser will open the Elastic MapReduce interface for monitoring your job flow. If that doesn't happen, the URL for viewing your job flow is included in Rail-RNA's output, and you can copy and paste it into your browser's address bar.\n\n\nExplore. Click on things. You'll first see something like\n\n\n\n\n. If you click on Steps, you'll see\n\n\n\n\n. These are the steps Rail-RNA will march through to align the human example. If you click on Bootstrap Actions, you'll see\n\n\n\n\n. When an Elastic MapReduce cluster starts up, its nodes are not equipped with the software Rail needs to run a job flow. Bootstrap actions are executed before the job flow begins to install this required software. Once the job flow is finished, all the software and any temporary files that have accumulated on the cluster are wiped. This is a virtue of using cloud computing to do your bioinformatics: you start with \nexactly\n the same machines and software configuration, making your results highly reproducible.\n\n\nIt's possible you'll want to click on Terminate soon after starting the job flow to avoid incurring any charges---and that's fine, but you may also want to delete Rail-RNA's detritus on S3 using the \nconsole\n. This includes the directories \ns3://this-is-the-bucket-name-you-make-up/human_example.dependencies\n and \ns3://this-is-the-bucket-name-you-make-up/human_example.logs\n. When Rail-RNA launches a job on Elastic MapReduce, it copies itself to S3 so the version of Rail you use in the cloud is precisely the version you use on your computer. This copy is stored in the directory that ends with \ndependencies\n. The directory that ends with \nlogs\n is used by Elastic MapReduce to record stats on your job flow. This is what you view in the Elastic MapReduce web interface. Another directory---\ns3://this-is-the-bucket-name-you-make-up/human_example.intermediate\n---will appear on S3 if you run the job flow from end to end. This directory stores intermediate data from one step that's streamed into some other step of the Rail-RNA pipeline. It shouldn't be touched until a job flow is complete, but afterwards, feel free to axe it. Both the \nintermediate\n and \ndependencies\n directories are purged automatically after four days to avoid your incurring extra S3 charges without your noticing. You can toggle how many days these directories remain on S3 with the \n--intermediate-lifetime\n command-line parameter.\n\n\nHere's a screenshot of the job flow in progress.\n\n\n\n\nIf you decided to continue the job flow, and your steps don't look something like this, something's gone wrong. Can't figure out what? Complain in the \nGitter\n.\n\n\nWhen the job flow is complete---\n\n\n\n\n---you can browse the outputs in the \nconsole\n. You'll find them at \ns3://this-is-the-bucket-name-you-make-up/human_example\n. The AWS CLI can also be used to list the contents of a directory like so:\n\n\ntestcomputer:~ testuser$ aws s3 ls s3://this-is-the-bucket-name-you-make-up/human_example/\n                           PRE alignments/\n                           PRE coverage_bigwigs/\n                           PRE cross_sample_results/\n                           PRE introns_and_indels/\n\n\n\n\nYou can download all the results to your computer like so:\n\n\nmkdir /home/testuser/human_example\ncd /home/testuser/human_example\naws s3 cp s3://this-is-the-bucket-name-you-make-up/human_example/ ./ --recursive\n\n\n\n\n. \nWarning: transfers from S3 to non-EC2 computers \ncost money\n.\n\n\nTo divide the human example up into preprocess and align job flows, try the following commands.\n\n\nrail-rna prep elastic -m https://raw.githubusercontent.com/nellore/rail/master/ex/hg19_example.manifest -o s3://this-is-the-bucket-name-you-make-up/human_example --core-instance-type c3.2xlarge --master-instance-type c3.2xlarge -c 1\n\nrail-rna align elastic -m https://raw.githubusercontent.com/nellore/rail/master/ex/hg19_example.manifest -a hg19 -o s3://this-is-the-bucket-name-you-make-up/human_example --core-instance-type c3.2xlarge --master-instance-type c3.2xlarge -c 1\n\n\n\n\nYou should now know enough figure out how to use Rail-RNA to align your RNA-seq data! Refer to the \nDeliverables\n and \nReference\n for further details on, respectively, changing output formats and command-line parameters.", 
            "title": "Tutorial"
        }, 
        {
            "location": "/tutorial/#trial-and-error", 
            "text": "We made a serious attempt to design Rail-RNA for people who don't read manuals to discourage improper use of the software. In general, you can get started by entering  rail-rna  in the shell. You'll obtain the following output, perhaps with a different version number.  error: too few arguments\nusage: rail-rna  job flow   mode   [args] \n\n   job flow        {prep, align, go}\n                     prep: preprocess reads listed in a required manifest\n                       file (specified with --manifest)\n                     align: align preprocessed reads (specified with --input)\n                     go: perform prep and align in succession\n   mode            {local, parallel, elastic}\n                     local: run Rail-RNA on this computer\n                     parallel: run Rail-RNA on all active IPython engines\n                     elastic: run Rail-RNA on Amazon Elastic MapReduce.\n                       Requires that the user sign up for Amazon Web Services\n\n\u2200 Rail-RNA v0.1.8c by Abhi Nellore (anellore@jhu.edu; nellore.github.io)\n\nRail-RNA is a scalable MapReduce pipeline that can analyze many RNA-seq\ndatasets at once. To view help for a given combination of  job flow  and mode , specify both, then add -h/--help.  It's quite possible to figure out how a substantial fraction Rail-RNA works by trial and error. Follow the prompts and fix your errors, which Rail tries to explain in detail when they're encountered. Please let us know in the  Gitter  if you're confused by any errors output. If you prefer to be guided through some examples, read on.", 
            "title": "Trial and error"
        }, 
        {
            "location": "/tutorial/#modes-and-job-flows", 
            "text": "Rail-RNA has three modes---    local , which runs the software on a single machine on up to as many processing cores as available. By default, Rail-RNA runs on the number of processing cores it detects on a machine less one to avoid monopolizing a single machine's resources. To adjust the number of cores on which Rail is run, use the  -p/--num-processes  command-line parameter described under Reference.    elastic , which runs the software on an Amazon Elastic MapReduce computer cluster in the cloud. This costs money: you rent computing capacity (on  Elastic Compute Cloud , or EC2) and storage (on  Simple Storage Service , or S3) from Amazon for the duration of your job flow and for as long as you keep your outputs in the cloud. Price information is  here . For a medium-size job (up to ~100 RNA-seq samples with ~50 million reads each), we tend to use a cluster of 40 c3.2xlarge machines, which costs $21/hour on demand but perhaps less than half that number on the spot market in the US Standard zone ( us-east-1 ). Learn more about the spot market and bidding on compute capacity  here .    parallel , which runs on an IPython Parallel cluster whose profile is specified at the command line. You must set up the IPython Parallel cluster yourself.    ---and three job flows---    prep , which if necessary downloads input FASTQ/FASTA files from a remote server and casts it in a form amenable for further analysis. This job flow must always be run before the  align  job flow.    align , which aligns preprocessed data and writes outputs explained in  Deliverables . Use the  --deliverables  option described there to control which of Rail-RNA's terminal outputs should be written.    go , which runs the  prep  and  align  job flows in succession.    To run some combination of mode and job flow, start your command with  rail-rna  mode   job flow   . Get help by entering  rail-rna  mode   job flow  -h  The reason for separating the  prep  and  align  job flows is that you may prefer to run these flows on different numbers of processing cores: if downloads are throttled by the remote server, and only a small number of threads can download input files concurrently, then you can limit the size of the computer cluster in  elastic  mode (with the  -c/--core-instance-count  parameter described in Reference) or the number of concurrently running threads in  local  mode (with the  -p/--num-processes  parameter described in Reference).  Align some RNA-seq samples with us in  local ,  parallel , and  elastic  modes below. We assume your login name is  testuser , and your home directory is  /home/testuser .  local  and  parallel  modes: Drosophila examples  Rail-RNA wraps both  Bowtie 1  and  Bowtie 2 , so you will need  both  Bowtie 1 and Bowtie 2 indexes of a genome assembly to perform alignment. It's easiest to download one of the  Illumina iGenomes , collections of reference sequences and indexes for popularly studied organisms. Here are explicit instructions:  Download the Drosophila melanogaster build dm3 iGenome, available  here . This is a 783-MB file. We assume you downloaded the dm3 iGenome to the directory  /home/testuser/Downloads . Unpack it by entering  cd /home/testuser/Downloads\ntar xvzf Drosophila_melanogaster_UCSC_dm3.tar.gz  in the shell. This could take a while, but once it's done, the Bowtie 1 index basename should be  /home/testuser/Downloads/Drosophila_melanogaster/UCSC/dm3/Sequence/BowtieIndex/genome , while the Bowtie 2 index basename should be  /home/testuser/Downloads/Drosophila_melanogaster/UCSC/dm3/Sequence/Bowtie2Index/genome .  Warning:  You may think you already have Bowtie 1 and 2 indexes for a given genome assembly---perhaps dm3---but the contigs in one may not be exactly the same as the contigs in the other. When working with any reference in Rail-RNA, it is important to ensure that the Bowtie 1 and 2 indexes are built from the same FASTA. Check the  Bowtie 1 documentation  and  Bowtie 2 documentation  for information on how to build Bowtie indexes from reference FASTAs.  Now open your browser, and navigate to the URL https://raw.githubusercontent.com/nellore/rail/master/ex/dm3_example.manifest . You'll see the following text.  http://verve.webfactional.com/dm3_example_1_left.fastq       0       http://verve.webfactional.com/dm3_example_1_right.fastq        0       dm3_example-1-1\nhttp://verve.webfactional.com/dm3_example_2_left.fastq       0       http://verve.webfactional.com/dm3_example_2_right.fastq        0       dm3_example-2-1  This is a Rail-RNA manifest file, and it is required for all Rail-RNA runs. Its format mirrors the manifest file format of  Myrna , a predecessor of Rail. Each line corresponds to a different RNA-seq sample. A line for a single-end sample looks like this---  FASTQ/FASTA URL (tab) URL MD5 checksum or 0 (tab) sample label   ---while a line for a paired-end sample looks like this---  FASTQ/FASTA URL 1 (tab) URL 1 MD5 checksum or 0 (tab) FASTQ/FASTA URL 2 (tab) URL 2 MD5 checksum or 0 (tab) sample label   . URLs can be on the local filesystem, on the web, or if the  AWS CLI  is installed, on Amazon S3. If an input file is not on the local filesystem, it will be downloaded by Rail. Manifest files may be hosted remotely as well.  Our Drosophila example is composed of two paired-end biological replicates, and the raw data is hosted at  http://verve.webfactional.com  . Let's create a new  railtests  directory in  testuser 's home directory for running all our examples.   mkdir -p /home/testuser/railtests\ncd /home/testuser/railtests  Preprocessing and aligning the test data in  local  mode takes a single command:  rail-rna go local -x /home/testuser/Downloads/Drosophila_melanogaster/UCSC/dm3/Sequence/BowtieIndex/genome /home/testuser/Downloads/Drosophila_melanogaster/UCSC/dm3/Sequence/Bowtie2Index/genome -m https://raw.githubusercontent.com/nellore/rail/master/ex/dm3_example.manifest  . The run should complete after a few minutes. You can browse the output by entering  cd /home/testuser/railtests/rail-rna_out\nls  You'll find four directories:  alignments    cross_sample_results\ncoverage_bigwigs  introns_and_indels  See  Deliverables  for information on how to interpret what's in these directories.  Commonly used options in  local  mode are   -p/--num-processes , which controls the number of processes Rail-RNA runs simultaneously. By default, Rail uses as many processing cores as your computer has less one so it doesn't monopolize resources. You may want to run on all cylinders by setting this equal to the number of available processing cores.   -o/--output , which changes the output directory. By default, this is  rail-rna_out  in the current directory.  See the Reference section for a comprehensive description of command-line parameters.  We could have run Rail-RNA in two steps: by preprocessing first and subsequently aligning. You can try this yourself by running the following commands in sequence.  cd /home/testuser/railtests\nrail-rna prep local -m https://raw.githubusercontent.com/nellore/rail/master/ex/dm3_example.manifest -o dmel_prepped -p 1\nrail-rna align local -i dmel_prepped -m https://raw.githubusercontent.com/nellore/rail/master/ex/dm3_example.manifest -x home/testuser/Downloads/Drosophila_melanogaster/UCSC/dm3/Sequence/BowtieIndex/genome /home/testuser/Downloads/Drosophila_melanogaster/UCSC/dm3/Sequence/Bowtie2Index/genome -f  The  rail-rna prep local  command above is executed on a single thread (with  -p 1 ) to ensure that only one download is performed at a time, which would be useful if our downloads were throttled. In the  rail-rna align local  command, the parameter  -f/--force  tells Rail to overwrite any existing outputs. You should end up with exactly the same output you obtained when you ran the  rail-rna go local  command.  Now you'll run an example that will break Rail. Navigate to the URL https://raw.githubusercontent.com/nellore/rail/master/ex/bad.manifest . The manifest will look like this:  http://verve.webfactional.com/bad.fastq       0        bad-1-1  It's a single-end sample called \"bad,\" presumably because it's not good. Visit http://verve.webfactional.com/bad.fastq next. The file will be downloaded, or it will be displayed in your browser. If it's downloaded, navigate to the appropriate folder at the shell prompt, and enter  cat bad.fastq  . Either way, you'll see  @badrecord\nATACAGATGACAGATGACAGGGTAGAGACAAATAGACAGATGACGATGGACAGATGACAGATAGAACAGATAGAGA\n+\nIIIIIIIIIIIIII\n@goodrecord\nATGGCATCAGTCAAGTCAAGATTACTAGTAGCCATACAAGATACATCGTTTAACGATTGTGGCACATACGTCACCA\n+\nIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII  There's one sequence labeled \"badrecord\" and another labeled \"goodrecord\". \"badrecord\" is bad because its read sequence isn't the same length as its quality sequence. Without being told otherwise, Rail-RNA chokes on bad records, but it's good to see how it chokes to learn how to diagnose problems. Run Rail-RNA on the bad manifest like so---  cd /home/testuser/railtests\nrail-rna go local -x /home/testuser/Downloads/Drosophila_melanogaster/UCSC/dm3/Sequence/BowtieIndex/genome /home/testuser/Downloads/Drosophila_melanogaster/UCSC/dm3/Sequence/Bowtie2Index/genome -m https://raw.githubusercontent.com/nellore/rail/master/ex/bad.manifest -o ./bad  ---and you'll ultimately obtain output like this:  \u2200 Rail-RNA v0.1.8c\nStarted job flow on Saturday, Jul 18, 2015 at 07:36:29 PM EDT.\n\n~.oOo. \n\n00h:00m:00s |___| Step 1/24: Count lines in input files\n00h:00m:01s |___|     Completed 1 task.\n00h:00m:01s |___|     Deleted temporary files.\n00h:00m:01s |___| Step 2/24: Assign reads to preprocessing tasks\n00h:00m:01s |___|     Partitioned 1 input into tasks.\n00h:00m:03s |___|     Completed 1 task.\n00h:00m:03s |___|     Deleted temporary files.\n00h:00m:03s |___| Step 3/24: Preprocess reads\n*****Errors encountered*****\nStreaming command  cat /var/folders/rs/zytvc1753p9_bth4lrhbm7c80000gn/T/tmpCxbBKB/0 | /usr/local/raildotbio/pypy-2.5.0-osx64/bin/pypy /usr/local/raildotbio/rail-rna/rna/steps/preprocess.py --nucs-per-file=100000000 --gzip-output --push=/home/testuser/railtests/rail-rna_logs/preprocess/push --gzip-level 3   --bin-qualities  /home/testuser/railtests/rail-rna_logs/preprocess/0 2 /home/testuser/railtests/rail-rna_logs/preprocess/dp.map.log/0.0.log  failed; exit level was 1.\nJob flow failed on Saturday, Jul 18, 2015 at 07:36:34 PM EDT. Run time was 5.503 seconds.\nTo start this job flow from where it left off, run:\n/usr/local/raildotbio/pypy-2.5.0-osx64/bin/pypy /usr/local/raildotbio/rail-rna/dooplicity/emr_simulator.py -j /home/testuser/railtests/rail-rna_logs/resume_flow_WDEZ24GVC0TM.json -b /usr/local/raildotbio/rail-rna/rna/driver/rail-rna.txt -l /home/testuser/railtests/rail-rna_logs/flow.2015-07-18T19:36:27.934937.log -f --max-attempts 1 --num-processes 3\nTraceback (most recent call last):\n  File  app_main.py , line 75, in run_toplevel\n  File  /usr/local/raildotbio/rail-rna/dooplicity/emr_simulator.py , line 1963, in  module \n    args.scratch, args.common, args.sort, args.max_attempts)\n  File  /usr/local/raildotbio/rail-rna/dooplicity/emr_simulator.py , line 1719, in run_simulation\n    max_attempts=max_attempts\n  File  /usr/local/raildotbio/rail-rna/dooplicity/emr_simulator.py , line 1290, in execute_balanced_job_with_retries\n    raise RuntimeError\nRuntimeError  Rail is telling us that something went wrong with a command during preprocessing. Note the following.    Rail gives you a command you can use to resume a job flow if it's failed for a fixable reason. One possible reason is that you ran out of space on disk during a job flow, and you need to delete some of your files. You can highlight and copy the command that resumes your job flow with  Command+C  on a Mac or  CTRL+C  in Linux. If somehow you lose the resume command, you'll also find it in the last written file whose extension is  .log  in the log directory  /home/testuser/railtests/rail-rna_logs . Enter   ls -tr /home/testuser/railtests/rail-rna_logs/*.log | tail -n 1  to get its path.    There's a log file in the command that failed, right after the  2 . This file will tell you why the job flow failed. Open it with  less :  less /home/testuser/dmel/rail-rna_logs/preprocess/dp.map.log/0.0.log  . (You should  less  whatever log file appears for you after the  2 ). At the bottom of the file is the exception that made the job flow fail:  Created local destination directory \"/var/folders/rs/zytvc1753p9_bth4lrhbm7c80000gn/T/tmpQJHduB\".\nRetrieving URL \"http://verve.webfactional.com/bad.fastq\"...\nRange of quality values found from random sample of 10000 records is (73, 73).\nGuessed Phred64 encoding.\nTraceback (most recent call last):\n  File \"app_main.py\", line 75, in run_toplevel\n  File \"/usr/local/raildotbio/rail-rna/rna/steps/preprocess.py\", line 863, in  module \n    mover=mover)\n  File \"/usr/local/raildotbio/rail-rna/rna/steps/preprocess.py\", line 557, in go\n    ) % (line_numbers[i], sources[i])\nAssertionError: Length of read sequence does not match length of quality string at line 4 of file \"/var/folders/rs/zytvc1753p9_bth4lrhbm7c80000gn/T/tmpQJHduB/bad.fastq\".  . So Rail noticed  @badrecord  was a bad record and failed. You can have Rail ignore bad records during preprocessing using the  --ignore-bad-records  command-line parameter:  rail-rna go local -x /home/testuser/Downloads/Drosophila_melanogaster/UCSC/dm3/Sequence/BowtieIndex/genome /home/testuser/Downloads/Drosophila_melanogaster/UCSC/dm3/Sequence/Bowtie2Index/genome -m https://raw.githubusercontent.com/nellore/rail/master/ex/bad.manifest -o ./bad -f --ignore-bad-records  . This job flow should succeed, and you'll end up with exactly one aligned read in the directory  /home/testuser/railtests/bad/alignments . Ignoring bad records may be useful when you're analyzing hundreds of samples and, for example, one file is truncated, but you'd like to analyze all its available reads anyway. Sometimes, you can't anticipate the integrity of the data you're analyzing, but you don't want your job flow to fail because of a handful of bad records.    To test Rail-RNA in  parallel  mode, you should have IPython installed. If the Rail-RNA installer didn't prompt you to install it, you already have it. Detailed instructions on starting IPython clusters over many different cluster configurations may be found  here . The IPython documentation around this link teaches you how to create a profile for a cluster configuration and how to start a cluster. An IPython cluster is nothing but a collection of Python interpreters (\"engines\") running on processing cores distributed across some networked computers. Rail-RNA does not start an IPython cluster for you; rather, it detects a running IPython cluster and runs itself over that. You can choose the IPython profile Rail-RNA should use with the  --ipython-profile  command-line parameter. If left unspecified, this is taken to be the default profile.  For testing purposes, you can run an IPython cluster on just your machine by entering  ipcluster start -n  k   , where  k  is the number of IPython engine processes you want to run.  k  is analogous to the  -p/--num-processes  parameter of Rail-RNA in local mode. Now rerun the first Drosophila example except in  parallel  mode by entering  rail-rna go parallel -x /home/testuser/Downloads/Drosophila_melanogaster/UCSC/dm3/Sequence/BowtieIndex/genome /home/testuser/Downloads/Drosophila_melanogaster/UCSC/dm3/Sequence/Bowtie2Index/genome -m https://raw.githubusercontent.com/nellore/rail/master/ex/dm3_example.manifest -f  What happens is pretty unimpressive: Rail runs like it does in local mode. But IPython Parallel lends Rail versatility: there are many different IPython cluster configurations you can set up on, say, your institutional computer cluster. But there is one caveat: in  parallel  mode, you  must  make sure the output directory (specified with  -o/--output ) and the log directory (specified with  --log ) are at paths accessible to  all  the nodes in your cluster running IPython engines. Rail-RNA aggregates intermediate data in the log directory between any two successive steps, and all nodes must be able to stream data from that directory to complete their assigned tasks. Moreover, outputs must go to the same place, and some paths on a cluster refer to different places on different nodes. For example, you probably shouldn't make a subdirectory of  /tmp  your output or log directory on a conventional computer cluster because  /tmp  tends to be a node-local temporary directory.  elastic  mode: a human example  Warning: running this example will cost money , but probably no more than US$5. Read our  disclaimer  before using  elastic  mode.  You should have performed  these  steps to set up the AWS CLI and Elastic MapReduce before attempting the example.  Visit https://raw.githubusercontent.com/nellore/rail/master/ex/hg19_example.manifest in your browser. Listed are two single-end human samples with just 20,000 reads each. They were generated with expression profiles of two  GEUVADIS  lymphoblastoid cell line samples in a way we describe in our  paper , but because there are so few reads, you probably couldn't tell which GEUVADIS samples we used if you didn't have the sample labels in the manifest file.  Let's use Elastic MapReduce to both preprocess and align these data. Since you'll be storing the results on Amazon's  Simple Storage Service  (S3), you should first read up on  working with buckets . The short story is that on S3, a bucket is something like a directory in a filesystem, except   Unless you specify otherwise, only your account can access it.  Bucket names are globally unique: if someone else has taken a bucket name in any Amazon region, you can't have it.  Underscores in bucket names are a bad idea when you use Elastic MapReduce. They cause weird problems. Don't ask why; just go with it.  A bucket is located in a specific Amazon region---that is, a bucket has a physical location in an Amazon data center, and that's where your files go.   You can create a bucket at the command line using the AWS CLI. Enter  aws s3 mb s3://this-is-the-bucket-name-you-make-up --region  a valid region   . A list of valid regions is available  here . Since you specified your default region when configuring the AWS CLI, if you leave the  --region  part out above, the bucket will be created in your default region---typically  us-east-1 .  But you don't  have  to create a bucket yourself before using Rail; if it doesn't already exist, Rail will automatically create the bucket you specify in your output directory path for you. We went through this exercise so you understand that the root of your output directory on S3 will always be a bucket in some region. Note that you can use Amazon's  web interface  to manipulate buckets, too.  If you've set up the AWS CLI properly, you can preprocess and align the example human dataset in the cloud with one command:  rail-rna go elastic -m https://raw.githubusercontent.com/nellore/rail/master/ex/hg19_example.manifest -a hg19 -o s3://this-is-the-bucket-name-you-make-up/human_example --core-instance-type c3.2xlarge --master-instance-type c3.2xlarge -c 1  . This command reserves two  c3.2xlarge  EC2 instances  to execute a Rail-RNA job flow that dumps its output to  s3://this-is-the-bucket-name-you-make-up/human_example . =There's always one master instance, whose type is specified with the  --master-instance-type  command-line parameter above; and the  -c  parameter specifies the number of core instances, whose type is specified with  --core-instance-type . The master instance manages the Hadoop cluster that will run your job, scheduling and coordinating tasks that are executed on slave nodes---which for Rail-RNA are generally core instances. We recommend using at least 40  c3.2xlarge  core instances for every hundred RNA-seq samples with 50 million reads each. You might also consider using  c3.8xlarge  instances, each of which has four times the resources of a  c3.2xlarge  instance; so in this case, the recommended ratio is at least 10  c3.8xlarge  instances for every hundred RNA-seq samples with 50 million reads each. For our small example, we use only one core instance. The  -a hg19  parameter specifies that the input data should be aligned to hg19.  Warning : Your job flow will execute in the default region you chose when you set up the AWS CLI unless you tack a  --region  desired region  onto the command above. If your output bucket is in a region different from your Elastic MapReduce cluster, transferring data between the cluster and S3 will take longer and slow down your job.   Executing the  rail-rna go elastic ...  command above gives the following output.  testcomputer:~ testuser$ rail-rna go elastic -m https://raw.githubusercontent.com/nellore/rail/master/ex/hg19_example.manifest -a hg19 -o s3://this-is-the-bucket-name-you-make-up/human_example --core-instance-type c3.2xlarge --master-instance-type c3.2xlarge -c 1\nLoading...\nChecked all files listed in manifest file.\nCopied Rail-RNA and bootstraps to S3.\n\n\u2200 Rail-RNA v0.1.8c\nStarted job flow submission script on Saturday, Jul 18, 2015 at 08:50:34 PM EDT.\n\n~.oOo. \n\n00h:00m:00s |___| Read job flow from input JSON.\n00h:00m:10s |___| Verified that output directories on S3 are writable.\n00h:00m:23s |___| Set up output directories on S3.\n00h:00m:25s |___| Submitted job flow.\n*****Job flow ID is j-2NSJ3SJPGKC58 .*****\n*****Submission can be monitored at https://console.aws.amazon.com/elasticmapreduce/?region=eu-west-1#cluster-details:j-2NSJ3SJPGKC58 .*****\n00h:00m:25s |___| Opening URL in default browser, if possible. .oOo.~\n\nFinished job flow submission script on Saturday, Jul 18, 2015 at 08:51:00 PM EDT. Run time was 25.789 seconds.  If all goes well, your browser will open the Elastic MapReduce interface for monitoring your job flow. If that doesn't happen, the URL for viewing your job flow is included in Rail-RNA's output, and you can copy and paste it into your browser's address bar.  Explore. Click on things. You'll first see something like   . If you click on Steps, you'll see   . These are the steps Rail-RNA will march through to align the human example. If you click on Bootstrap Actions, you'll see   . When an Elastic MapReduce cluster starts up, its nodes are not equipped with the software Rail needs to run a job flow. Bootstrap actions are executed before the job flow begins to install this required software. Once the job flow is finished, all the software and any temporary files that have accumulated on the cluster are wiped. This is a virtue of using cloud computing to do your bioinformatics: you start with  exactly  the same machines and software configuration, making your results highly reproducible.  It's possible you'll want to click on Terminate soon after starting the job flow to avoid incurring any charges---and that's fine, but you may also want to delete Rail-RNA's detritus on S3 using the  console . This includes the directories  s3://this-is-the-bucket-name-you-make-up/human_example.dependencies  and  s3://this-is-the-bucket-name-you-make-up/human_example.logs . When Rail-RNA launches a job on Elastic MapReduce, it copies itself to S3 so the version of Rail you use in the cloud is precisely the version you use on your computer. This copy is stored in the directory that ends with  dependencies . The directory that ends with  logs  is used by Elastic MapReduce to record stats on your job flow. This is what you view in the Elastic MapReduce web interface. Another directory--- s3://this-is-the-bucket-name-you-make-up/human_example.intermediate ---will appear on S3 if you run the job flow from end to end. This directory stores intermediate data from one step that's streamed into some other step of the Rail-RNA pipeline. It shouldn't be touched until a job flow is complete, but afterwards, feel free to axe it. Both the  intermediate  and  dependencies  directories are purged automatically after four days to avoid your incurring extra S3 charges without your noticing. You can toggle how many days these directories remain on S3 with the  --intermediate-lifetime  command-line parameter.  Here's a screenshot of the job flow in progress.   If you decided to continue the job flow, and your steps don't look something like this, something's gone wrong. Can't figure out what? Complain in the  Gitter .  When the job flow is complete---   ---you can browse the outputs in the  console . You'll find them at  s3://this-is-the-bucket-name-you-make-up/human_example . The AWS CLI can also be used to list the contents of a directory like so:  testcomputer:~ testuser$ aws s3 ls s3://this-is-the-bucket-name-you-make-up/human_example/\n                           PRE alignments/\n                           PRE coverage_bigwigs/\n                           PRE cross_sample_results/\n                           PRE introns_and_indels/  You can download all the results to your computer like so:  mkdir /home/testuser/human_example\ncd /home/testuser/human_example\naws s3 cp s3://this-is-the-bucket-name-you-make-up/human_example/ ./ --recursive  .  Warning: transfers from S3 to non-EC2 computers  cost money .  To divide the human example up into preprocess and align job flows, try the following commands.  rail-rna prep elastic -m https://raw.githubusercontent.com/nellore/rail/master/ex/hg19_example.manifest -o s3://this-is-the-bucket-name-you-make-up/human_example --core-instance-type c3.2xlarge --master-instance-type c3.2xlarge -c 1\n\nrail-rna align elastic -m https://raw.githubusercontent.com/nellore/rail/master/ex/hg19_example.manifest -a hg19 -o s3://this-is-the-bucket-name-you-make-up/human_example --core-instance-type c3.2xlarge --master-instance-type c3.2xlarge -c 1  You should now know enough figure out how to use Rail-RNA to align your RNA-seq data! Refer to the  Deliverables  and  Reference  for further details on, respectively, changing output formats and command-line parameters.", 
            "title": "Modes and job flows"
        }, 
        {
            "location": "/deliverables/", 
            "text": "Choosing deliverables\n\n\nThere are several classes of outputs. Each is described in a different section below. You can toggle which outputs are written with the \n-d/--deliverables\n command-line parameter for \ngo\n and \nalign\n job flows. By default \n--deliverables\n is set to \ntsv idx bam bw bed\n, which is all the outputs described below. But for example, you might decide that you don't need the alignment BAMs. In this case, you can invoke \n--deliverables tsv idx bw bed\n. This will make Rail-RNA take less time to run and will also save you space---which is especially useful on S3, where storage is rented.\n\n\ntsv\n: cross-sample matrices\n\n\nThese are gzip-compressed cross-sample outputs. They appear in the \ncross_sample_results\n subdirectory of the output directory.\n\n\n\n\ncounts.tsv.gz\n: A labeled matrix whose (i, j)th element takes the form \"x\nij\n,y\nij\n\", where x\nij\n is the number of primary alignments in sample i to group j, and y\nij\n is the number of uniquely aligning reads in group j. Here, a group is a chromosome, the set of unmapped reads U, the set of mapped reads M, or the set of all reads A; and \"uniquely aligning read\" means that there is exactly one alignment of the read with the highest alignment score. For group U, x\nij\n = y\nij\n. For group M, x\nij\n is the sum of all the x\nij\ns in the chromosome columns. For group A, x\nij\n is the total number of reads, while y\nij\n is the sum of the y\nij\ns in groups U and M.\n\n\n\n\njunctions.tsv.gz\n: a labeled matrix whose (i, j)th element is the number of reads in sample j covering intron i. Introns are in the first column. Each one takes the form\n\n\nchromosome\n;\nstrand (+/-)\n;\n1-based start position (inclusive)\n;\n1-based end position (exclusive)\n.\n\n\n\nSample names are in the first row.\n  * \n[insertion|deletion]s.tsv.gz\n: a labeled matrix whose (i, j)th element is the number of reads in sample j covering [insertion|deletion] i. [Insertion|deletion]s are in the first column. An insertion takes the form\n\n\nchromosome\n;\ninserted base sequence\n;\n1-based position of the last base before the insertion\n;\n1-based position of the last base before the insertion\n\n\n\n\nA deletion takes the form\n\n\nchromosome\n;\ndeleted base sequence\n;\n1-based position of the first deleted base\n;\n1-based position of the first base after the deletion\n\n\n\n\n\n\n\n\nnormalization.tsv.gz\n: each row takes the form \nsample name\n(tab)\n--normalize-percentile\n normalization factor for coverage vector composed of primary alignments\n(tab)\n--normalize-percentile\n normalization factor for coverage vector composed of unique alignments\n. The default percentile is \n0.75\n, corresponding to \nupper-quartile normalization\n.\n\n\n\n\n\n\nidx\n: isofrag index\n\n\nThis refers to the file \nisofrags.tar.gz\n that appears in the \ncross_sample_results\n subdirectory of the output directory. In general, it should be left gzipped; it can be used to align a new sample to the transcript fragments obtained from an old Rail-RNA run. Say you've aligned 500 samples from the same tissue type with Rail, and you think the list of introns you found is pretty comprehensive. Now say you just obtained another 10 samples from the same tissue type, and you want to align them. You can skip looking for novel junctions in those 10 samples by passing Rail-RNA's \ngo\n or \nalign\n job flow the path to this file as an argument of the \n--isofrag-idx\n command-line parameter.\n\n\nbw\n: coverage vectors\n\n\nThese are coverage bigWigs, and they appear in the \ncoverage_bigwigs\n subdirectory of the output directory. There are two for each sample. One is called \nsample name\n.bw\n, and it encodes coverage of the genome by primary alignments. The other is called \nsample name\n.unique.bw\n, and it encodes coverage of the genome by uniquely aligning reads, where a uniquely aligning read has exactly one alignment with the highest alignment score. There are also coverage bigwigs for each chromosome. \n[mean|median].\nchr\n.bw\n encodes the [mean|median] coverage at each base on chromosome \nchr\n by primary alignments, and \n[mean|median].\nchr\n.bw\n encodes the [mean|median] coverage at each base on chromosome \nchr\n by uniquely aligning reads. Leo Collado-Torres describes how to use bigWigs as input to downstream analysis tools like \nderfinder\n, \nedgeR-robust\n, and \nDESeq2\n \nhere\n. Note that a bigWig is typically an order of magnitude smaller than a BAM.\n\n\nbam\n: alignments\n\n\nThese are alignment BAMs and their corresponding indexes (BAIs) that appear in the \nalignments\n subdirectory of the output directory. By default, there's one BAM per sample per chromosome taking the form \nalignments.\nsample name\n.\nchr\n.bam\n. You can use the \n--do-not-output-bam-by-chr\n command-line parameter for \ngo\n and \nalign\n job flows to output one BAM per sample. In that case, the filename takes the form \nalignments.\nsample name\n.bam\n. Note that outputting BAMs by chromosome is in general faster because it increases parallelism.\n\n\nbed\n: introns and indels\n\n\nThese are BED files that mirror TopHat 2's output BEDs. They appear in the \nintrons_and_indels\n subdirectory of the output directory. For each sample \nsample name\n, there are three BEDs: \njunctions.\nsample name\n.bed\n, \ninsertions.\nsample name\n.bed\n, and \ndeletions.\nsample name\n.bed\n. Quotes in the following statements are from the \nTopHat 2 manual\n. Recall that BED always uses 0-based coordinates.\n  * \njunctions.\nsample name\n.bed\n: \"Each junction consists of two connected BED blocks, where each block is as long as the maximal overhang of any read spanning the junction. The score is the number of alignments spanning the junction.\"\n  * \ndeletions.\nsample name\n.bed\n: \"chromLeft refers to the first genomic base of the deletion.\"\n  * \ninsertions.\nsample name\n.bed\n: \"chromLeft refers to the last genomic base before the insertion.\"", 
            "title": "Deliverables"
        }, 
        {
            "location": "/deliverables/#choosing-deliverables", 
            "text": "There are several classes of outputs. Each is described in a different section below. You can toggle which outputs are written with the  -d/--deliverables  command-line parameter for  go  and  align  job flows. By default  --deliverables  is set to  tsv idx bam bw bed , which is all the outputs described below. But for example, you might decide that you don't need the alignment BAMs. In this case, you can invoke  --deliverables tsv idx bw bed . This will make Rail-RNA take less time to run and will also save you space---which is especially useful on S3, where storage is rented.  tsv : cross-sample matrices  These are gzip-compressed cross-sample outputs. They appear in the  cross_sample_results  subdirectory of the output directory.   counts.tsv.gz : A labeled matrix whose (i, j)th element takes the form \"x ij ,y ij \", where x ij  is the number of primary alignments in sample i to group j, and y ij  is the number of uniquely aligning reads in group j. Here, a group is a chromosome, the set of unmapped reads U, the set of mapped reads M, or the set of all reads A; and \"uniquely aligning read\" means that there is exactly one alignment of the read with the highest alignment score. For group U, x ij  = y ij . For group M, x ij  is the sum of all the x ij s in the chromosome columns. For group A, x ij  is the total number of reads, while y ij  is the sum of the y ij s in groups U and M.   junctions.tsv.gz : a labeled matrix whose (i, j)th element is the number of reads in sample j covering intron i. Introns are in the first column. Each one takes the form  chromosome ; strand (+/-) ; 1-based start position (inclusive) ; 1-based end position (exclusive) .  Sample names are in the first row.\n  *  [insertion|deletion]s.tsv.gz : a labeled matrix whose (i, j)th element is the number of reads in sample j covering [insertion|deletion] i. [Insertion|deletion]s are in the first column. An insertion takes the form  chromosome ; inserted base sequence ; 1-based position of the last base before the insertion ; 1-based position of the last base before the insertion   A deletion takes the form  chromosome ; deleted base sequence ; 1-based position of the first deleted base ; 1-based position of the first base after the deletion     normalization.tsv.gz : each row takes the form  sample name (tab) --normalize-percentile  normalization factor for coverage vector composed of primary alignments (tab) --normalize-percentile  normalization factor for coverage vector composed of unique alignments . The default percentile is  0.75 , corresponding to  upper-quartile normalization .    idx : isofrag index  This refers to the file  isofrags.tar.gz  that appears in the  cross_sample_results  subdirectory of the output directory. In general, it should be left gzipped; it can be used to align a new sample to the transcript fragments obtained from an old Rail-RNA run. Say you've aligned 500 samples from the same tissue type with Rail, and you think the list of introns you found is pretty comprehensive. Now say you just obtained another 10 samples from the same tissue type, and you want to align them. You can skip looking for novel junctions in those 10 samples by passing Rail-RNA's  go  or  align  job flow the path to this file as an argument of the  --isofrag-idx  command-line parameter.  bw : coverage vectors  These are coverage bigWigs, and they appear in the  coverage_bigwigs  subdirectory of the output directory. There are two for each sample. One is called  sample name .bw , and it encodes coverage of the genome by primary alignments. The other is called  sample name .unique.bw , and it encodes coverage of the genome by uniquely aligning reads, where a uniquely aligning read has exactly one alignment with the highest alignment score. There are also coverage bigwigs for each chromosome.  [mean|median]. chr .bw  encodes the [mean|median] coverage at each base on chromosome  chr  by primary alignments, and  [mean|median]. chr .bw  encodes the [mean|median] coverage at each base on chromosome  chr  by uniquely aligning reads. Leo Collado-Torres describes how to use bigWigs as input to downstream analysis tools like  derfinder ,  edgeR-robust , and  DESeq2   here . Note that a bigWig is typically an order of magnitude smaller than a BAM.  bam : alignments  These are alignment BAMs and their corresponding indexes (BAIs) that appear in the  alignments  subdirectory of the output directory. By default, there's one BAM per sample per chromosome taking the form  alignments. sample name . chr .bam . You can use the  --do-not-output-bam-by-chr  command-line parameter for  go  and  align  job flows to output one BAM per sample. In that case, the filename takes the form  alignments. sample name .bam . Note that outputting BAMs by chromosome is in general faster because it increases parallelism.  bed : introns and indels  These are BED files that mirror TopHat 2's output BEDs. They appear in the  introns_and_indels  subdirectory of the output directory. For each sample  sample name , there are three BEDs:  junctions. sample name .bed ,  insertions. sample name .bed , and  deletions. sample name .bed . Quotes in the following statements are from the  TopHat 2 manual . Recall that BED always uses 0-based coordinates.\n  *  junctions. sample name .bed : \"Each junction consists of two connected BED blocks, where each block is as long as the maximal overhang of any read spanning the junction. The score is the number of alignments spanning the junction.\"\n  *  deletions. sample name .bed : \"chromLeft refers to the first genomic base of the deletion.\"\n  *  insertions. sample name .bed : \"chromLeft refers to the last genomic base before the insertion.\"", 
            "title": "Choosing deliverables"
        }, 
        {
            "location": "/reference/", 
            "text": "", 
            "title": "Reference"
        }
    ]
}